S3 101
  - S3 provides developers and IT teams with secure, durable, highly-scalable object storage
  - S3 has a simple web service interface to store and retrieve any amount of data from anywhere on the web
  - S3 is not for operating systems or Databases
  - S3 is a safe place to store your files
  - S3 is object storage based, not block storage based
  - With S3, your data is spread across multiple devices and facilities
  - S3 is object based - i.e. allows you to upload files
  - S3 files can be from 0 Bytes to 5 TB
  - S3 has unlimited storage
  - With S3, files are stored in buckets, which are similar to folders
  - S3 has a universal name space, that is, bucket names must be unique globally; similar to a DNS address
  - When you upload a file into S3 you will receive an HTTP 200 code if the upload was successful
  - S3 Data Consistency: two modes
    - Read after Write consistency for PUTS of new objects
    - Eventual consistency for overwrite PUTS and DELETES (can take some time to propagate)
  - S3 is a simple key-value store
    - S3 is object based; objects consist of the following:
      - a Key, which is simply the name of the object
      - a Value, which is simply the data, which is made up of a series of bytes
      - a Version ID, which is important for versioning
      - Metadata, which is data about the data you are storing
      - Subresources, which are bucket-specific configuration:
        - Bucket policies
        - Access Control Lists
        - Cross Origin Resource Sharing (CORS); files located in one bucket to access files located in another bucket
        - Transfer Acceleration, which is a service which allows you to accelerate file transfers when upload many files into S3
  - S3 is built for 99.99% availability
  - Amazon guarantees 99.9% availability
  - Amazon guarantees 99.999999999% durability for S3 information (11 9s)
  - S3 has tiered storage available
  - S3 has lifecycle management
  - S3 has versioning
  - S3 has encryption
  - You can secure access to your data using:
    - Access Control Lists
    - Bucket Policies
  - S3 Storage Tiers
    - Regular S3
      - 99.99% availability, 99.999999999% durability, stored redundantly across multiple devices in multiple facilities;
        designed to sustain a loss of 2 facilities concurrently
    - S3 IA (Infrequently Accessed)
      - For data that is accessed less frequently, but requires rapid access when needed
      - Lower fee than S3, but you are charged a retrieval fee every time you retrieve the data
    - One-Zone IA
      - Same as IA however data is stored in a single AZ only
      - Still 99.999999999% durability
      - Only 99.5% availability
      - Costs 20% less than regular IA
    - Reduced Redundancy Storage
      - Designed to provide 99.99% durability and 99.99% availability of objects over a given year
      - Used for data that can be recreated if lost, e.g. thumbnails
    - Glacier
      - Very inexpensive, but used for archival only
      - Optimized for data that is infrequently accessed
      - It takes 3 to 5 hours to restore data from Glacier
    - S3 Intelligent Tiering
      - Suitable for data which has unknown or unpredictable access patterns
      - 2 Tiers
        - frequent access
        - infrequent access
      - Automatically moves your data to the most cost-effective tier based on how frequently you access each object within a bucket
      - If an object is not accessed for 30 consecutive days, it gets automatically moved to the infrequent access tier
      - As soon as an object in the infrequent access tier is accessed, it is moved to the frequent access tier
      - 99.99999999999% durability
      - 99.9% availability over a given year
      - Helps optimize cost
      - No fees for accessing your data but a small monthly fee for monitoring/automation $0.0025 per 1,000 objects
 - S3 Charges
   - Storage per GB
   - Requests (Get, Put, Copy, etc.)
   - Storage Management pricing
     - Inventory, Analytics, and Object Tags
   - Data management pricing
     - Data transferred out of S3
     - Free to transfer in to S3
   - Transfer Acceleration
     - Use of CloudFront to optimize transfers
 - Exam Tips
   - Example S3 bucket url: https://s3-eu-west-1.amazonaws.com/bucketname
S3 Security
 - By default, all newly created buckets are private
 - You can setup access control to your buckets using:
   - Bucket Policies: applied at the bucket level
   - Access Control Lists: applied at the object level
 - S3 buckets can be configured to create access logs, which log all requests made to the S3 bucket. These logs can be written to another bucket
 - Bucket policies are written in JSON
 - All versions of a versioned S3 bucket are kept in the same bucket
 - S3 object-level logging records any api level activity using AWS CloudTrail, at an additional cost
 - S3 has two different types of encryption:
   - AES-256: uses server-side encryption with AWS S3-Managed Keys (SSE-S3)
   - AWS-KMS: uses server-side encryption with AWS KMS-Managed Keys (SSE-KMS)
 - You can enable S3 CloudWatch request metrics, which monitor requests in your bucket for an additional cost
   - gives performance metrics for S3
 - S3 has public access settings
   - Used to enforce that buckets do not allow public access to data.
   - You can also configure S3 to block public access at the account level.
 - You can grant public read-access to objects in the Access Control List
 - You can encrypt at rest at the bucket level using bucket policies or the object level using access control lists
 - If the bucket policy does not allow public access, you cannot upload an object into the bucket and make that object publicly accessible using the Access Control List
S3 Encryption
 - In transit
   - SSL/TLS (Transport Layer Security, will replace SSL)
     - generally means using https to transmit data
 - At Rest
   - Server-side encryption - 3 types
     - S3 managed keys - SSE-S3
       - AWS manages the keys for you, rotate keys on a defined frequency
       - uses AES-256 bit encryption
     - AWS Key Management Service, managed keys - SSE-KMS
       - AWS manages the keys for you
       - uses an envelope key that encrypts your encryption key
       - gives an audit trail which records the use of your encryption key
       - can use your own key, or the default AWS key
     - Server-side encryption with customer provided keys - SSE-C
       - AWS manages the encryption and decryption but you manage your own keys
 - Client-side encryption
   - you encrypt the files yourself before you upload to S3
 - Enforcement of S3 Encryption
   - Every time a file is uploaded to S3, a PUT request is initiated
   - If the file is to be encrypted at upload time, the x-amz-server-side-encryption parameter will be included in the request header
     - two options are currently available
       - x-amz-server-side-encryption: AES256 (SSE-S3 - S3 managed keys)
       - x-amz-server-side-encryption: ams:kms (SSE-KMS - KMS managed keys)
     - when this parameter is included in the header of the PUT request, it tells S3 to encrypt the object at the time of upload, using the specified encryption method
     - you can enforce the use of server-side encryption by using a bucket policy which denies any S3 PUT request which does not include the x-amz-server-side-encryption
       parameter in the request header
CloudFront
 - A Content Delivery Network (CDN) is a system of distributed servers (network) that deliver webpages and other web content to a user based on the:
   - geographic location of the user
   - the origin of the web page
   - a content delivery server
 - Edge Locations are collections of servers in dispersed geographic locations
   - used by CloudFront to cache web content close to geographically dispersed users
   - can write content into Edge Locations (PUT an object to them) as well as read from them
   - separate from AZs or Regions
 - Origin
   - the origin of all the files that the CDN will distribute
   - Origins can be S3 buckets, EC2 instances, an ELB, or Route53
 - Distribution
   - the name given to the CDN
   - consists of a collection of edge locations
   - Two types of distributions
     - Web Distribution
       - Typically used for websites
     - RTMP (Real Time Messaging Protocol)
       - Used for media streaming
       - Adobe Flash, multi-media content
 - CloudFront also works with any non-AWS origin server
 - CloudFront accelerates S3 Transfer Acceleration
   - S3 Transfer Acceleration takes advantage of CloudFront's globally distributed edge locations
   - When the data being transferred arrives at an edge location the remaining transfer moves over AWS's optimized network path
 - You can clear cached objects from your CloudFront edge locations but you will be charged
 - Can have multiple origins for a distribution
 - You can clear your CloudFront cache by invalidating objects
S3 Performance Optimization (START HERE)
 - S3 is designed to support very high request rates
   - If your S3 buckets are routinely receiving > 100 PUT/LIST/DELETE or > 300 GET requests per second, then there are some best practice
     guidelines that will help optimize S3 Performance
   - The guidance is based on the type of workload you are running
     - GET-intensive workloads
       - use CloudFront content delivery service to get best performance
       - CloudFront will cache your most frequently accessed objects and will reduce latency for your GET requests
     - Mixed Request Type Workloads
       - a mix of GET, PUT, DELETE, GET Bucket - the key names you use for your objects can impact performance workloads
       - S3 uses the key name to determine which partition an object will be stored in
       - The use of sequential key names e.g. names prefixed with a timestamp or alphabetical sequence increases the likelihood
         of having multiple objects stored on the same partition
       - For heavy workloads this can cause I/O issues and contention
       - By using a random prefix to key names (like a hex hash), you can force S3 to distribute your keys across multiple partitions, distributing the I/O workload
Performance Update
 - S3 can support at least 3,500 put requests per second
 - S3 can support at least 5,500 get requests per second
 - Now you no longer need to randomized key names to achieve faster performance
 - Logical and sequential naming patterns can now be used without any performance implication
S3 Summary
 - S3 website url format http://bucketname.s3-website-regionname.amazonaws.com
S3 Quiz
 - S3 provides unlimited storage
   - true (correct)
   - false
 - What is the HTTP code you would see once you successfully place a file in an S3 bucket?
   - 524
   - 200 (correct)
   - 312
   - 404
 - You are hosting a static website in an S3 bucket that uses Java script to reference assets in another S3 bucket. For some reason, these assets are not displaying when users browse to the site. What could be the problem?
   - You haven not enabled Cross Origin Resource Sharing (CORS) on the bucket where the assets are stored (correct)
   - Amazon S3 does not support Javascript
   - You cannot use one S3 bucket to reference another S3 bucket
   - You need to open port 80 on the appropriate security group in which the S3 bucket is located
 - The minimum file size allowed on S3 is 1 byte
   - true
   - false (correct)
 - How does S3 determine which partition to use to store files?
   - The bucket name determines which partition the file is stored in
   - S3 automatically stores your files on a random partition
   - The key name determines which partition the file is stored in (correct)
   - By default, all files in the same bucket are stored on the same partition
 - Your application is consistently reading and writing 100s of objects per second to S3 and your workload is steadily rising. What can you do to achieve the best performance from S3?
   - Configure an additional bucket and distribute the files evenly between the two buckets
   - Configure a CloudFront CDN and use the S3 bucket as the origin
   - Add a hex hash prefix to the objects key name (correct)
   - Add a hex hash suffix to the objects key name
 - What is the maximum file size that can be stored on S3?
   - 4TB
   - 2TB
   - 1TB
   - 5TB (correct)
 - You are using S3 in AP-Northeast to host a static website in a bucket called acloudguru. What would the new URL endpoint be?
   - http://acloudguru.s3-website-ap-southeast-1.amazonaws.com
   - https://s3-ap-northeast-1.amazonaws.com/acloudguru/
   - http://acloudguru.s3-website-ap-northeast-1.amazonaws.com (correct)
   - http://www.acloudguru.s3-website-ap-northeast-1.amazonaws.com
 - When you first create an S3 bucket, this bucket is publicly accessible by default
   - true
   - false (correct)
 - Which feature of AWS can you use to configure S3 to allow one S3 bucket to access files in another S3 bucket?
   - IAM Role
   - CORS (correct)
   - Bucket ACL
   - Bucket Policy
 - If you want to enable a user to download your private data directly from S3, you can insert a pre-signed URL into a web page before giving it to your user.
   - true (correct)
   - false
 - Which of the following encryption methods are supported in S3? (Choose 3)
   - SSE-C (correct)
   - SSE-AES
   - SSE-KMS (correct)
   - SSE-S3 (correct)
 - What is the largest size file you can transfer to S3 using a PUT operation?
   - 1GB
   - 5GB (correct)
   - 100MB
   - 5TB
 - If you encrypt a bucket on S3, what type of encryption does AWS use?
   - International Data Encryption Algorithm (IDEA)
   - Data Encryption Standard (DES)
   - Advanced Encryption Standard (AES) 256 (correct)
   - Advanced Encryption Standard (AES) 128
 - Which of the following options allows users to have secure access to private files located in S3? (Choose 3)
   - CloudFront Origin Access Identity (correct)
   - Public S3 buckets
   - CloudFront Signed URLs (correct)
   - CloudFront Signed Cookies (correct)
Serverless 101

Lambda
  - Lambda is a compute service where you can upload your code and create a lambda function
  - AWS lambda takes care of provisioning and managing the servers that you use to run the code
  - You don't have to worry about operating systems, patching, scaling, etc.
  - You can use lambda in the following ways:
     - As an event-driven compute service where lambda runs your code in response to events
       - These events could be changes to data in an S3 bucket or an DynamoDB table
     - As a compute service to run your code in response to HTTP requests using API Gateway or API calls using AWS SDKs.
  - Lambda code can be written in these languages:
    - Node.js
    - Java
    - Python
    - C#
    - Go
  - Lambda is priced as follows:
    - Number of requests
      - first 1 million requests are free per month
      - $0.20 per 1 million requests after the first 1 million requests
    - Duration
      - Duration is calculated from the time your code begins executing until it returns or otherwise terminates, rounded up to the nearest 100ms
      - The price depends on the amount of memory you allocate to your function
      - You are charged $0.00001667 for every GB-second used
  - Lambda scales out (not up) automatically
  - AWS X-ray allows you to debug lambda function chains
  - Lambda can be used globally
    - you can use a lambda function to back up S3 buckets across regions
API Gateway
 - API Gateway is a fully managed service that lets developers publish, maintain, monitor, and secure APIs at any scale
 - Can use API Gateway to create APIs that access application code running on EC2 instances, code running in Lambda, or any other web application
 - API Gateway exposes HTTPS endpoints to define a RESTful API
 - API Gateway serverless-ly connects to services like Lambda & DynamoDB
 - API Gateway can send each API endpoint to a different target
 - Runs efficiently with low cost
 - Scales effortlessly
 - Track and control usage by API key
 - Throttle requests to prevent attacks
 - Connect to CloudWatch to log all requests for monitoring
 - Maintain multiple versions of your API
 - Defining an API in API Gateway:
   - Define an API (container)
   - Define resources and nested resources (URL paths)
     - For each resource:
       - Select supported HTTP methods (verbs)
       - Set security
       - Choose target (such as EC2, Lambda, DynamoDB, etc.)
       - Set request and response transformations
   - Deploy API to a stage
     - Uses API Gateway domain, by default
     - Can use a custom domain
     - Now supports AWS Certificate Manager: free SSL/TLS certs
 - Can enable API caching
   - Cache your endpoint's response
 - Same-origin-policy
   - allows scripts in a first web page to access data from a second web page only if both pages are served from the same origin
   - used to prevent cross-site scripting
   - enforced by web browsers
 - Cross-Origin-Resource-Sharing (CORS)
   - relaxes the same-origin-policy
   - Allows resources in a web page to be requested from a domain which is different from the domain which served the web page
   - the browser makes an HTTP OPTIONS call for a URL
   - The server returns a response that lists the domains approved for access from the URL
   - Or the server returns an error stating that the origin policy cannot be read at the remote resource, enable CORS on API Gateway
 - Lambda trigger services:
   - API Gateway
   - AWS IoT
   - Alexa Skills Kit
   - Alexa Smart Home
   - CloudFront
   - CloudWatch Events
   - CloudWatch Logs
   - CodeCommit
   - Cognito Sync Trigger
   - DynamoDB
   - Kinesis
   - S3
   - SNS
 - API Gateway integration point types
   - HTTP
   - Lambda Function
   - Mock: return a response purely using API Gateway mappings and transformations
   - AWS Service
   - VPC Link
Version Control with Lambda (START HERE)
   - When you use versioning with Lambda, you can publish one or more versions of your Lambda function
   - Each version of your Lambda function has a unique ARN
   - After you publish a version it is immutable
   - There are two types of ARNs associated with a Lambda function
     - Qualified ARN - The function ARN with the version suffix
       - arn:aws:lambda:aws-region:acct-id:function:hwlloworld:$LATEST
     - Unqualified ARN - The function ARN without the suffix
       - arn:aws:lambda:aws-region:acct-id:function:hwlloworld
   - Alias
     - After publishing your Lambda function, then create an alias to it, such as PROD, you can then use the PROD alias to invoke this version of the function
     - If you make changes and publish this new version, you can point the PROD alias to the new version.
     - If you decide to roll back to the old version, you just repoint the alias to the old version
   - You can use versioning to create splits between traffic, such as blue/green deployments
     - You cannot use $LATEST in version splitting
Step Functions
   - Step Functions allow you to visualize and test your serverless applications
   - Provides a graphical console to arrange and visualize the components of your application as a series of steps
   - Automatically triggers and tracks each step, and retries when there are errors
   - Logs the state of each step, so you can diagnose and debug
   - Can have sequential steps
   - Can have branching steps
   - Can have parallel steps
   - Use Amazon States Language to create steps
X-Ray
   - X-Ray is a service that collects data about requests that your application serves, and provides tools you can use to view, filter, and gain insights into that data
     to identify issues and opportunities for optimization
   - For any traced request to your application, you can see details of the request and response, as well as calls your application makes to downstream
     AWS resources, microservices, databases, and HTTP web APIs
   - Use the X-Ray SDK inside your application
      - the X-Ray SDK sends information (in JSON) to the X-Ray Daemon, which sends the JSON to the X-Ray API
      - the X-Ray creates a visualization of the functioning of your app, which it displays in the X-Ray Console
      - the AWS SDK and the AWS CLI can communicate directly with the X-Ray Daemon and/or the X-Ray API
   - The X-Ray SDK provides
      - Interceptors to add to your code to trace incomming HTTP requests
      - Client handlers to instrument AWS SDK clients that your application uses to call other AWS services
      - An HTTP client to use to instrument calls to other internal and external HTTP web services
   - X-Ray integrates with the following AWS services
      - Elastic Load Balancing
      - Lambda
      - API Gateway
      - EC2
      - Elastic Beanstalk
   - X-Ray supported languages:
      - Java
      - Go
      - Node.js
      - Python
      - Ruby
      - .Net
Advanced API Gateway
  -
