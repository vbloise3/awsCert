{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "import io\n",
    "import sagemaker.amazon.common as smac\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Read from csv or someother location like s3.\n",
    "# Download from your S3 bucket the census data CSV file based on the publically available census data from the ML repository curated by the University of California, Irvine\n",
    "from io import StringIO\n",
    "s3 = boto3.resource('s3')\n",
    "bucket_name = 'machine-learning-exam' # place the adult_census.csv file in a bucket in your account\n",
    "object_key = 'Real_estate_valuation_data_set.csv'\n",
    "\n",
    "# Load the data into a pandas dataframe \n",
    "\n",
    "csv_obj = s3.Object(bucket_name, object_key)\n",
    "csv_string = csv_obj.get()['Body'].read().decode('utf-8')\n",
    "\n",
    "dataset = pd.read_csv(StringIO(csv_string))\n",
    "dataset.head()\n",
    "#dataset = pd.read_csv(\"Bio_Train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the data and split it between train and test datasets on a 70% 30% split respectively\n",
    "train_data, test_data = np.split(dataset.sample(frac=1, random_state=1729), [int(0.7 * len(dataset))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the features and labels.\n",
    "feature_dataset = dataset[['X1 transaction date', 'X2 house age', 'X3 distance to the nearest MRT station', \n",
    "                           'X4 number of convenience stores', 'X5 latitude', 'X6 longitude' ]]\n",
    "features = np.array(feature_dataset.values).astype('float32')\n",
    "\n",
    "label_dataset= dataset[['Y house price of unit area']]\n",
    "labels = np.array(label_dataset.values).astype('float32')\n",
    "labels_vec = np.squeeze(np.asarray(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(buffer, features, labels_vec)\n",
    "buffer.seek(0)\n",
    "\n",
    "key = 'linearregression'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buffer)\n",
    "s3_training_data_location = 's3://{}/{}/train/{}'.format(bucket, prefix, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://machine-learning-exam/sagemaker/xgboost-regression/output\n"
     ]
    }
   ],
   "source": [
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "linear_container = get_image_uri(boto3.Session().region_name, 'linear-learner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 03:27:55 Starting - Starting the training job...\n",
      "2020-02-14 03:27:56 Starting - Launching requested ML instances......\n",
      "2020-02-14 03:29:03 Starting - Preparing the instances for training......\n",
      "2020-02-14 03:30:19 Downloading - Downloading input data.."
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Provide the container, role, instance type and model output location\n",
    "linear = sagemaker.estimator.Estimator(linear_container,\n",
    "                                       role=role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c4.xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Provide the number of features identified during data preparation\n",
    "# Provide the predictor_type \n",
    "\n",
    "linear.set_hyperparameters(feature_dim=6,\n",
    "                           mini_batch_size=4,\n",
    "                           predictor_type='regressor')\n",
    "\n",
    "# Train the model using the previously prepared test data and validate the \n",
    "#data by providing the validation data.\n",
    "\n",
    "linear.fit({'train': s3_training_data_location})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
