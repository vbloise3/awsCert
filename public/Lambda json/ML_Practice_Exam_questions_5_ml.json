[
  {
    "id": "796",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "ML Exam Practice Questions",
      "questionType": "multiple choice 1",
      "question": "As a consultant working for an optical manufacturer, you have been asked to develop an automated streaming solution for high volume data generated by Amazon Connect. The data must be highly available and stored in your enterprise data lake. The solution must preprocess and group data into batches based on metadata values before storing the data in the data lake. The primary considerations are data durability and read performance from the data lake.\n\nYou have decided to create a Kinesis Data Stream to collect data. Which of the following would complete the solution and meet the requirements?",
      "answers": [
        "Create a custom Spark streaming job on Amazon EMR that pulls data from the Kinesis Data Stream, and then writes partitioned Parquet files to the data lake.",
        "Create an AWS Lambda function to read batches of records from the Kinesis Data Stream, and then write JSON files to the data lake.",
        "Create a Kinesis Data Firehose that reads data from the Kinesis Data Stream, and then writes buffered data to partitioned Parquet files stored in the data lake.",
        "Create multiple Kinesis Data Firehose streams and implement a custom sharding mechanism to batch the data. Assign the data lake as the destination for the Firehose."
      ],
      "correctAnswer": ["Create a Kinesis Data Firehose that reads data from the Kinesis Data Stream, and then writes buffered data to partitioned Parquet files stored in the data lake."]
    }
  }
]