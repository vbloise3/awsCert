[
  {
    "id": "3",
    "category": "Cloud Concepts",
    "info": {
      "subcategory": "Processing",
      "questionType": "multiple choice 1",
      "question": "You are a data engineer in a mobile software company that is building a data lake to hold information about bike rentals in cities where you have fleets of bikes to rent. Your data lake needs to hold the bike rental information captured from the bike rental mobile app and from sensors on the rental bikes. Your management team wants to do historical analysis on the bike rental data so a daily ingestion frequency works for your scenario. You have decided to stream this data into your data processing system via \nKinesis Data Streams. You have written a KCL module to write your mobile app and sensor data in CSV format to an S3 bucket in batches on a daily basis. You now need to operationalize the remainder of your data lake components. Which of the following will allow you to orchestrate your data processing flow in the most efficient and performant way?",
      "answers": [
        "Use an AWS Step Functions state machine to orchestrate steps that 1) crawl your ingested CSV data, 2) run a Glue ETL job to convert the CSV to Parquet, 3) Start up your query EMR ingestion cluster",
        "Use a Glue Workflow to: crawl the CSV data, run an ETL job to convert the CVS data to Parquet data, crawl the Parquet data. Then on completion of the Glue Workflow event, run a Step Functions state machine to start up your query EMR cluster",
        "Use a Glue Workflow to: crawl the CSV data. Then on completion of the Glue Workflow event, run a Step Functions state machine to: 1) run a Glue ETL job to convert the CSV to Parquet, 2) after step one completes, start up your query EMR cluster",
        "Use an AWS Step Functions state machine to: 1) crawl your ingested CSV data, 2) run a Glue ETL job to convert the CSV to Parquet, 3) run a Glue crawler to crawl the Parquet data, 4) after step one completes, start up your query EMR cluster"
      ],
      "correctAnswer": ["Use a Glue Workflow to: crawl the CSV data, run an ETL job to convert the CVS data to Parquet data, crawl the Parquet data. Then on completion of the Glue Workflow event, run a Step Functions state machine to start up your query EMR cluster"]
    }
  }
]